
import './nodePolyfills';

// NOTE: Using livekit-client (not server-sdk) because worker joins as a participant
import {
  Room,
  RoomEvent,
  RemoteTrack,
  RemoteTrackPublication,
  RemoteParticipant,
  Track
} from 'livekit-client';
import { config } from '../config/config';
import { ParticipantAudioBuffer } from './audioProcessor';
import { runTranslationPipeline } from './aiService';
import { LanguageCode, ParticipantMetadata } from '../types';

// AudioFrame type for Node.js environment
interface AudioFrame {
  data: Buffer;
  sampleRate: number;
  channels: number;
  samplesPerChannel: number;
}

/**
 * Translation Worker Class
 * Manages audio interception and translation for a single room
 */
export class TranslationWorker {
  private room: Room;
  private audioBuffers: Map<string, ParticipantAudioBuffer> = new Map();
  private isActive = false;
  private processingQueue: Set<string> = new Set(); // Track ongoing processing

  constructor(
    private roomName: string,
    private workerIdentity: string = `translation-worker-${Date.now()}`
  ) {
    // Create Room instance (LiveKit SDK)
    this.room = new Room();

    console.log(
      `[Worker] Created translation worker for room: ${roomName}\n` +
      `  Worker identity: ${workerIdentity}`
    );
  }

  /**
   * Start the worker
   * Connects to LiveKit room and starts listening for audio
   * 
   * @param accessToken - JWT token for room access (generated by livekitService)
   */
  async start(accessToken: string): Promise<void> {
    if (this.isActive) {
      console.warn('[Worker] Already active, skipping start');
      return;
    }

    try {
      console.log(`[Worker] Connecting to room: ${this.roomName}...`);
      console.log(`[Worker] Environment check:`);
      console.log(`  - navigator exists: ${typeof navigator !== 'undefined'}`);
      console.log(`  - window exists: ${typeof window !== 'undefined'}`);
      console.log(`  - LiveKit URL: ${config.livekit.url}`);
      console.log(`  - Token length: ${accessToken.length} chars`);
      console.log(`  - Room state before connect: ${this.room.state}`);

      // Connect to LiveKit server
      await this.room.connect(config.livekit.url, accessToken);

      this.isActive = true;

      console.log(
        `[Worker] âœ“ Connected to room as "${this.workerIdentity}"\n` +
        `  Room: ${this.roomName}\n` +
        `  Room state: ${this.room.state}\n` +
        `  URL: ${config.livekit.url}`
      );

      // Set up event listeners
      this.setupEventListeners();

      // Subscribe to existing participants' tracks
      await this.subscribeToExistingTracks();
    } catch (error) {
      console.error('[Worker] âœ— Failed to connect:', error);
      throw error;
    }
  }

  /**
   * Set up event listeners for room events
   * 
   * KEY EVENTS:
   * - trackSubscribed: New audio track available (participant started speaking)
   * - trackUnsubscribed: Audio track ended
   * - participantDisconnected: Participant left (cleanup buffers)
   */
  private setupEventListeners(): void {
    // Event: New track subscribed (audio/video track from a participant)
    this.room.on(
      RoomEvent.TrackSubscribed,
      (
        track: RemoteTrack,
        publication: RemoteTrackPublication,
        participant: RemoteParticipant
      ) => {
        this.handleTrackSubscribed(track, publication, participant);
      }
    );

    // Event: Track unsubscribed (participant stopped publishing)
    this.room.on(
      RoomEvent.TrackUnsubscribed,
      (
        track: RemoteTrack,
        publication: RemoteTrackPublication,
        participant: RemoteParticipant
      ) => {
        this.handleTrackUnsubscribed(track, participant);
      }
    );

    // Event: Participant disconnected (cleanup)
    this.room.on(
      RoomEvent.ParticipantDisconnected,
      (participant: RemoteParticipant) => {
        this.handleParticipantDisconnected(participant);
      }
    );

    // Event: Room disconnected (error or intentional)
    this.room.on(RoomEvent.Disconnected, () => {
      console.log('[Worker] Disconnected from room');
      this.isActive = false;
    });

    console.log('[Worker] Event listeners registered');
  }

  /**
   * Subscribe to audio tracks from all existing participants
   * Called when worker first joins the room
   */
  private async subscribeToExistingTracks(): Promise<void> {
    const participants = Array.from(this.room.remoteParticipants.values());

    console.log(
      `[Worker] Found ${participants.length} existing participants in room`
    );

    for (const participant of participants) {
      // Iterate through participant's tracks
      for (const publication of participant.trackPublications.values()) {
        if (publication.track && publication.kind === Track.Kind.Audio) {
          this.handleTrackSubscribed(
            publication.track as RemoteTrack,
            publication,
            participant
          );
        }
      }
    }
  }

  /**
   * Handle new audio track subscription
   * 
   * This is where audio frames start flowing!
   * 
   * FLOW:
   * 1. Participant publishes audio track
   * 2. LiveKit notifies us via TrackSubscribed event
   * 3. We create audio buffer for this participant
   * 4. We listen for audio frames on the track
   * 5. Each frame is added to the buffer
   * 6. When buffer is full, we process it through AI pipeline
   */
  private handleTrackSubscribed(
    track: RemoteTrack,
    publication: RemoteTrackPublication,
    participant: RemoteParticipant
  ): void {
    // Only process audio tracks
    if (track.kind !== Track.Kind.Audio) {
      return;
    }

    // Skip if this is a translated track (to avoid feedback loops)
    const metadata = this.parseParticipantMetadata(participant.metadata);
    if (metadata?.isTranslatedTrack) {
      console.log(
        `[Worker] Skipping translated track from ${participant.identity}`
      );
      return;
    }

    console.log(
      `[Worker] ðŸŽ¤ Subscribed to audio track from ${participant.identity} ` +
      `(${participant.name || 'Unknown'})`
    );

    // Create audio buffer for this participant
    const buffer = new ParticipantAudioBuffer(
      participant.identity,
      participant.name || participant.identity,
      this.roomName
    );

    this.audioBuffers.set(participant.identity, buffer);

    // CRITICAL: Listen for audio frames
    // This is where raw PCM audio data arrives from LiveKit
    track.on('audioFrameReceived', (frame: AudioFrame) => {
      this.handleAudioFrame(frame, participant, metadata);
    });

    console.log(
      `[Worker] Audio buffer created for ${participant.name} ` +
      `(target language: ${metadata?.targetLanguage || 'unknown'})`
    );
  }

  /**
   * Handle incoming audio frames
   * 
   * AUDIO FRAME DETAILS:
   * - Arrives every 20ms (standard WebRTC packet time)
   * - Each frame contains ~960 samples at 48kHz
   * - Format: 16-bit PCM, mono or stereo
   * 
   * @param frame - Audio frame with PCM samples
   * @param participant - Participant who sent the audio
   * @param metadata - Participant's metadata (target language, etc.)
   */
  private async handleAudioFrame(
    frame: AudioFrame,
    participant: RemoteParticipant,
    metadata: ParticipantMetadata | null
  ): Promise<void> {
    const buffer = this.audioBuffers.get(participant.identity);
    if (!buffer) {
      return;
    }

    // Extract PCM samples from frame
    // Note: frame.data is a Buffer containing 16-bit PCM samples
    const samples = new Int16Array(
      frame.data.buffer,
      frame.data.byteOffset,
      frame.data.length / 2 // Divide by 2 because each sample is 2 bytes
    );

    // Add frame to buffer
    buffer.addFrame(samples);

    // Check if buffer is ready for processing
    if (buffer.isReady()) {
      // Prevent duplicate processing
      if (this.processingQueue.has(participant.identity)) {
        console.log(
          `[Worker] Skipping - already processing ${participant.identity}`
        );
        return;
      }

      // Mark as processing
      this.processingQueue.add(participant.identity);

      // Flush buffer and process (async, don't block frame reception)
      const audioBuffer = buffer.flush();
      if (audioBuffer) {
        // Process in background
        this.processAudioBuffer(audioBuffer, metadata)
          .finally(() => {
            // Remove from processing queue when done
            this.processingQueue.delete(participant.identity);
          });
      } else {
        this.processingQueue.delete(participant.identity);
      }
    }
  }

  /**
   * Process audio buffer through AI pipeline
   * 
   * This is where the magic happens:
   * 1. Get target languages from other participants
   * 2. For each target language:
   *    - Run AI pipeline (STT â†’ Translation â†’ TTS)
   *    - Publish translated audio to room
   * 3. Ensure original speaker doesn't hear their translation
   * 
   * @param audioBuffer - Buffered audio ready for processing
   * @param speakerMetadata - Speaker's metadata
   */
  private async processAudioBuffer(
    audioBuffer: AudioBuffer,
    speakerMetadata: ParticipantMetadata | null
  ): Promise<void> {
    console.log(
      `\n[Worker] ðŸ“¦ Processing audio buffer from ${audioBuffer.participantName}`
    );

    // Get all target languages from participants in the room
    const targetLanguages = this.getTargetLanguages(audioBuffer.participantId);

    if (targetLanguages.length === 0) {
      console.log('[Worker] No target languages found, skipping processing');
      return;
    }

    console.log(
      `[Worker] Target languages: ${targetLanguages.join(', ')} ` +
      `(${targetLanguages.length} translations needed)`
    );

    // Process for each target language
    for (const targetLang of targetLanguages) {
      try {
        const result = await runTranslationPipeline(audioBuffer, targetLang);

        if (result.success && result.tts) {
          // TODO: Publish translated audio back to LiveKit room
          // This requires:
          // 1. Converting MP3 to PCM
          // 2. Creating audio track
          // 3. Publishing with metadata (original speaker ID, target language)
          
          console.log(
            `[Worker] âœ“ Translation complete for ${targetLang}\n` +
            `  TODO: Publish audio to room (Phase 4)`
          );

          // For now, just log success
          // In Phase 4, we'll implement audio publishing
        }
      } catch (error) {
        console.error(
          `[Worker] âœ— Error processing translation for ${targetLang}:`,
          error
        );
      }
    }
  }

  /**
   * Get unique target languages from participants
   * Excludes the original speaker
   * 
   * @param excludeParticipantId - Participant to exclude (original speaker)
   * @returns Array of unique target language codes
   */
  private getTargetLanguages(excludeParticipantId: string): LanguageCode[] {
    const languages = new Set<LanguageCode>();

    // Iterate through all participants
    for (const participant of this.room.remoteParticipants.values()) {
      // Skip original speaker
      if (participant.identity === excludeParticipantId) {
        continue;
      }

      // Parse metadata to get target language
      const metadata = this.parseParticipantMetadata(participant.metadata);
      if (metadata?.targetLanguage && !metadata.isTranslatedTrack) {
        languages.add(metadata.targetLanguage);
      }
    }

    return Array.from(languages);
  }

  /**
   * Handle track unsubscribed
   * Clean up when participant stops publishing audio
   */
  private handleTrackUnsubscribed(
    track: RemoteTrack,
    participant: RemoteParticipant
  ): void {
    if (track.kind === Track.Kind.Audio) {
      console.log(
        `[Worker] ðŸ”‡ Unsubscribed from audio track: ${participant.identity}`
      );
      
      // Clear buffer
      const buffer = this.audioBuffers.get(participant.identity);
      if (buffer) {
        buffer.clear();
      }
    }
  }

  /**
   * Handle participant disconnected
   * Clean up resources when participant leaves
   */
  private handleParticipantDisconnected(
    participant: RemoteParticipant
  ): void {
    console.log(
      `[Worker] ðŸ‘‹ Participant disconnected: ${participant.identity} ` +
      `(${participant.name || 'Unknown'})`
    );

    // Remove audio buffer
    this.audioBuffers.delete(participant.identity);
    this.processingQueue.delete(participant.identity);
  }

  /**
   * Parse participant metadata JSON
   * Returns null if parsing fails
   */
  private parseParticipantMetadata(
    metadataJson?: string
  ): ParticipantMetadata | null {
    if (!metadataJson) {
      return null;
    }

    try {
      return JSON.parse(metadataJson) as ParticipantMetadata;
    } catch {
      return null;
    }
  }

  /**
   * Stop the worker and disconnect from room
   */
  async stop(): Promise<void> {
    if (!this.isActive) {
      return;
    }

    console.log(`[Worker] Stopping translation worker for room: ${this.roomName}`);

    // Clear all buffers
    this.audioBuffers.clear();
    this.processingQueue.clear();

    // Disconnect from room
    await this.room.disconnect();

    this.isActive = false;

    console.log('[Worker] âœ“ Translation worker stopped');
  }

  /**
   * Get worker status (for monitoring)
   */
  getStatus() {
    return {
      roomName: this.roomName,
      workerIdentity: this.workerIdentity,
      isActive: this.isActive,
      participantCount: this.room.remoteParticipants.size,
      activeBuffers: this.audioBuffers.size,
      processingQueueSize: this.processingQueue.size
    };
  }
}

/**
 * Worker Manager - Manages multiple translation workers
 * One worker per active room
 */
export class WorkerManager {
  private workers: Map<string, TranslationWorker> = new Map();

  /**
   * Start a translation worker for a room
   * 
   * @param roomName - Name of the room
   * @param accessToken - Access token for the worker
   */
  async startWorker(roomName: string, accessToken: string): Promise<void> {
    // Check if worker already exists
    if (this.workers.has(roomName)) {
      console.log(`[WorkerManager] Worker already running for room: ${roomName}`);
      return;
    }

    // Create and start new worker
    const worker = new TranslationWorker(roomName);
    await worker.start(accessToken);

    this.workers.set(roomName, worker);

    console.log(
      `[WorkerManager] âœ“ Worker started for room: ${roomName}\n` +
      `  Total active workers: ${this.workers.size}`
    );
  }

  /**
   * Stop a translation worker for a room
   */
  async stopWorker(roomName: string): Promise<void> {
    const worker = this.workers.get(roomName);
    if (!worker) {
      console.log(`[WorkerManager] No worker found for room: ${roomName}`);
      return;
    }

    await worker.stop();
    this.workers.delete(roomName);

    console.log(
      `[WorkerManager] âœ“ Worker stopped for room: ${roomName}\n` +
      `  Remaining active workers: ${this.workers.size}`
    );
  }

  /**
   * Stop all workers (cleanup on server shutdown)
   */
  async stopAll(): Promise<void> {
    console.log(`[WorkerManager] Stopping all workers (${this.workers.size})...`);

    const stopPromises = Array.from(this.workers.values()).map(worker =>
      worker.stop()
    );

    await Promise.all(stopPromises);
    this.workers.clear();

    console.log('[WorkerManager] âœ“ All workers stopped');
  }

  /**
   * Get status of all workers
   */
  getStatus() {
    return Array.from(this.workers.values()).map(worker => worker.getStatus());
  }
}

// Singleton instance
export const workerManager = new WorkerManager();

